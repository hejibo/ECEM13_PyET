{
 "metadata": {
  "name": "F. Eye Data Visualization"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd D:\\Dropbox\\WinPython-32bit-2.7.5.0\\my-code\\ipython-notebooks\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Dropbox\\WinPython-32bit-2.7.5.0\\my-code\\ipython-notebooks\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# psychopy.iohub related imports.....\n",
      "#\n",
      "import psychopy.iohub\n",
      "from psychopy.iohub.datastore.util import displayDataFileSelectionDialog, ExperimentDataAccessUtility\n",
      "from psychopy.iohub import EventConstants\n",
      "\n",
      "# A couple general Python imports....\n",
      "#\n",
      "import os\n",
      "import numpy as np\n",
      "import numpy\n",
      "\n",
      "# matplotlib related\n",
      "#\n",
      "import matplotlib.image as mpimg\n",
      "from matplotlib.collections import LineCollection\n",
      "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
      "\n",
      "# Workshop helper code..\n",
      "from Py4ET_2013 import *\n",
      "\n",
      "# Useful define for which sections of ipython notebook code should only run\n",
      "# when a code cell is explicitly launched, not just loaded.\n",
      "#\n",
      "script =  __name__ == '__main__'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#A. Eye Position Traces\n",
      "\n",
      "We've already seen a lot of that. ;)\n",
      "\n",
      "---\n",
      "\n",
      "#B. Accuracy and Precision Visualization\n",
      "\n",
      "We've done that already too. ;)\n",
      "\n",
      "---\n",
      "\n",
      "#C. Scan Paths\n",
      "\n",
      "**Scan path overlay plots** are generally created using either:\n",
      "\n",
      "- the eye tracker sample stream to generate the line segements for the scan path ( **Sample Based Scan Paths** )\n",
      "- the fixation (and possibly saccade) event stream generated by the eye trackking softwares eye event parser ( **Fixation / Event Based Scan Paths** )\n",
      "\n",
      "When a scan path overlay is sample based, areas of increased dwell time can usually be seen as the clustering of sample line segments within areas of the scene.\n",
      "\n",
      "When an event based scan path is used, it is common for each fixation event to be plotted as a circle shape, often with each fixation circle diameter being \n",
      "scaled by the fixation event duration. Saccade events can be represented as lines joining the relevent surrounding fixation events, or fixations can simply \n",
      "be joined by lines anchored to each fixations center point, thereby not attempting to use any available saccadic information (angle, duration, etc.).\n",
      "\n",
      "The scan path overlays to follow are created using an eye sample based approach. \n",
      "\n",
      "To aid in the visualization of the temportal order of the sample scan trace, a color map is used, with the color ramp normalized to the start and end time\n",
      "of the sample data being plotted (the trial time). This is often a more effective way of relaying temporal information on the 2D scan path plot compared\n",
      "to cluttering the scan path with numbers giving the trial time of eveny Nth scan path segment, or the sample index, etc. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "IMG_SIZE_SCALAR=2.0\n",
      "\n",
      "# Load sample data from a ioDtaStore HDF5 file..\n",
      "#\n",
      "results_by_trial=loadSampleData()\n",
      "\n",
      "orginal_plt_width,orginal_plt_height=plt.rcParams['figure.figsize'] \n",
      "plt.rcParams['figure.figsize'] =orginal_plt_width*IMG_SIZE_SCALAR,orginal_plt_height*IMG_SIZE_SCALAR\n",
      "\n",
      "for trial_data in results_by_trial:\n",
      "    # get the condition variable set used for the current trial\n",
      "    #\n",
      "    condition_set=trial_data.condition_set\n",
      "    \n",
      "    # Get the image name used for display during the trial\n",
      "    #\n",
      "    image_name=condition_set.IMAGE_NAME\n",
      "    trial_id=condition_set.trial_id\n",
      "    # load the image\n",
      "    #\n",
      "    trial_image_array=numpy.flipud(mpimg.imread(\"./images/\"+image_name))\n",
      "\n",
      "    # Get background image size\n",
      "    image_size=(trial_image_array.shape[1],trial_image_array.shape[0])\n",
      "    ihw,ihh=image_size[0]/2,image_size[1]/2\n",
      "\n",
      "    # Display image for illustrative purposes, 0,0 is image center.\n",
      "    #\n",
      "    plt.figure()\n",
      "    bip=plt.imshow(trial_image_array,origin='lower',extent=(-ihw, ihw,-ihh, ihh))\n",
      "    plt.title(\"Trial {0}: {1}\".format(trial_id,image_name))\n",
      "    \n",
      "    trial_data.left_gaze_x[trial_data.status//10>=2]=np.NaN\n",
      "    trial_data.left_gaze_y[trial_data.status//10>=2]=np.NaN\n",
      "    trial_data.left_pupil_measure1[trial_data.status//10>=2]=0\n",
      "    trial_data.right_gaze_x[trial_data.status%10>=2]=np.NaN\n",
      "    trial_data.right_gaze_y[trial_data.status%10>=2]=np.NaN\n",
      "    trial_data.right_pupil_measure1[trial_data.status%10>=2]=0\n",
      "    lx=trial_data.left_gaze_x\n",
      "    ly=trial_data.left_gaze_y\n",
      "    rx=trial_data.right_gaze_x\n",
      "    ry=trial_data.right_gaze_y\n",
      "    t=trial_data.time\n",
      "    \n",
      "    sample_points = np.array([lx, ly]).T.reshape(-1, 1, 2)\n",
      "    sample_segments = np.concatenate([sample_points[:-1], sample_points[1:]], axis=1)\n",
      "\n",
      "    scan_path_line_collection = LineCollection(sample_segments, cmap=plt.get_cmap('YlOrRd'),\n",
      "    norm=plt.Normalize(t.min(), t.max()))\n",
      "    scan_path_line_collection.set_array(t)\n",
      "    scan_path_line_collection.set_linewidth(2)\n",
      "\n",
      "    plt.gca().add_collection(scan_path_line_collection)\n",
      "    \n",
      "    cb=plt.colorbar(scan_path_line_collection)\n",
      "    cb.set_label(\"Trial Time (sec)\") \n",
      "    # draw smaple based scanpath\n",
      "    #sample_scan_path=matplotlib.lines.Line2D(lx, ly, linewidth=2, linestyle='-', color='r',marker='.', markersize=7,markerfacecolor='r',markeredgecolor='r',alpha=0.5)# markeredgewidth=None, markeredgecolor=None, markerfacecolor=None, markerfacecoloralt='none', fillstyle='full', antialiased=None, dash_capstyle=None, solid_capstyle=None, dash_joinstyle=None, solid_joinstyle=None, pickradius=5, drawstyle=None, markevery=None, **kwargs)\n",
      "    #plt.gca().add_line(sample_scan_path)\n",
      "\n",
      "plt.rcParams['figure.figsize'] =orginal_plt_width,orginal_plt_height"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#D. Eye Movement Animations\n",
      "\n",
      "Please start notebook without pllab in inline mode and open the \"Eye Position Animation\" notebook.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#E. Plotting Saccadic Reaction Times\n",
      "\n",
      "TBC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}